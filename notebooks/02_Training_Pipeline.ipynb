{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# 02 - Training Pipeline (End-to-End)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Setup: ensure dependencies are installed (skip on Kaggle if already present)\\n\",\n",
        "    \"import sys, subprocess\\n\",\n",
        "    \"req = '../requirements.txt'\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', '-r', req])\\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print('Install skipped or failed:', e)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"import os\\n\",\n",
        "    \"import json\\n\",\n",
        "    \"from pathlib import Path\\n\",\n",
        "    \"import pandas as pd\\n\",\n",
        "    \"import yaml\\n\",\n",
        "    \"\\n\",\n",
        "    \"PROJECT_ROOT = Path('..')\\n\",\n",
        "    \"CONFIG_PATH = PROJECT_ROOT / 'configs' / 'baseline_lgbm.yaml'\\n\",\n",
        "    \"TRAIN_PATH = PROJECT_ROOT / 'data' / 'train.csv'\\n\",\n",
        "    \"TEST_PATH = PROJECT_ROOT / 'data' / 'test.csv'\\n\",\n",
        "    \"\\n\",\n",
        "    \"with open(CONFIG_PATH, 'r') as f:\\n\",\n",
        "    \"    config = yaml.safe_load(f)\\n\",\n",
        "    \"config\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Data Loading & Preprocessing\\n\",\n",
        "    \"import sys\\n\",\n",
        "    \"sys.path.append(str(PROJECT_ROOT / 'src'))\\n\",\n",
        "    \"\\n\",\n",
        "    \"from preprocess import load_and_clean_data, save_label_mapping\\n\",\n",
        "    \"\\n\",\n",
        "    \"train_df, label_map = load_and_clean_data(str(TRAIN_PATH), config)\\n\",\n",
        "    \"test_df, _ = load_and_clean_data(str(TEST_PATH), config)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Save label mapping for inference\\n\",\n",
        "    \"label_map_path = (PROJECT_ROOT / config['paths']['label_mapping_path'])\\n\",\n",
        "    \"label_map_path.parent.mkdir(parents=True, exist_ok=True)\\n\",\n",
        "    \"with open(label_map_path, 'w') as f:\\n\",\n",
        "    \"    json.dump(label_map, f, indent=2)\\n\",\n",
        "    \"train_df.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Feature Engineering + Training (CV)\\n\",\n",
        "    \"from train import train_model\\n\",\n",
        "    \"\\n\",\n",
        "    \"oof_score, oof_df = train_model(train_df, config)\\n\",\n",
        "    \"print('OOF Macro F1:', oof_score)\\n\",\n",
        "    \"oof_df.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Inference on test and submission generation\\n\",\n",
        "    \"from predict import generate_predictions\\n\",\n",
        "    \"\\n\",\n",
        "    \"submission = generate_predictions(test_df, config['paths']['model_output_dir'], config)\\n\",\n",
        "    \"submission.head()\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## Explainability (SHAP)\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Demonstration with one fold model\\n\",\n",
        "    \"import joblib\\n\",\n",
        "    \"import shap\\n\",\n",
        "    \"from scipy import sparse\\n\",\n",
        "    \"from features import create_features, transform_tfidf\\n\",\n",
        "    \"\\n\",\n",
        "    \"model_dir = PROJECT_ROOT / config['paths']['model_output_dir']\\n\",\n",
        "    \"model_path = next(model_dir.glob('model_fold_*.pkl'))\\n\",\n",
        "    \"clf = joblib.load(model_path)\\n\",\n",
        "    \"fold = int(model_path.stem.split('_')[-1])\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Build a small sample feature matrix for SHAP\\n\",\n",
        "    \"sample = test_df.sample(100, random_state=42) if len(test_df) > 100 else test_df.copy()\\n\",\n",
        "    \"sample_feat, art, feat_cols = create_features(sample, config=config, is_train=False, fold=fold)\\n\",\n",
        "    \"tfidf_cfg = config['features'].get('tfidf', {})\\n\",\n",
        "    \"tfidf_cols = tfidf_cfg.get('use_text_columns', [])\\n\",\n",
        "    \"tfidf_prefix = config['paths'].get('vectorizer_prefix')\\n\",\n",
        "    \"if len(tfidf_cols) > 0 and tfidf_prefix:\\n\",\n",
        "    \"    vectorizer_path = PROJECT_ROOT / f\\\"{tfidf_prefix}_{fold}.pkl\\\"\\n\",\n",
        "    \"    tfidf_matrix = transform_tfidf(sample_feat[tfidf_cols[0]], str(vectorizer_path))\\n\",\n",
        "    \"else:\\n\",\n",
        "    \"    tfidf_matrix = None\\n\",\n",
        "    \"\\n\",\n",
        "    \"from scipy import sparse as sp\\n\",\n",
        "    \"X_sample = sp.hstack([sp.csr_matrix(sample_feat[feat_cols].astype(float).fillna(0.0).values), tfidf_matrix], format='csr') if tfidf_matrix is not None else sp.csr_matrix(sample_feat[feat_cols].astype(float).fillna(0.0).values)\\n\",\n",
        "    \"explainer = shap.TreeExplainer(clf.booster_) if hasattr(clf, 'booster_') else shap.Explainer(clf)\\n\",\n",
        "    \"shap_values = explainer(X_sample[:50])\\n\",\n",
        "    \"shap.plots.beeswarm(shap_values, max_display=15)\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"name\": \"python\",\n",
        "   \"version\": \"3.10\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 5\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DS_DA",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
